{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "from common.utils import Preprocessor, DefaultLogger\n",
    "from tplinker import (\n",
    "    HandshakingTaggingScheme,\n",
    "    DataMaker4Bert,\n",
    "    TPLinkerBert,\n",
    "    TPLinkerBiLSTM,\n",
    "    MetricsCalculator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Configuration manuelle pour éviter les problèmes de chemin\n",
    "train_config = {\n",
    "    \"exp_name\": \"nyt\",\n",
    "    \"data_home\": \".\",  # Utiliser le répertoire courant\n",
    "    \"train_data\": \"nyt_dataset.json\",  # Pointer directement vers le fichier JSON\n",
    "    \"valid_data\": \"nyt_dataset.json\",  # Utiliser le même fichier pour validation\n",
    "    \"rel2id\": \"rel2id.json\",\n",
    "    \"device_num\": 0,\n",
    "    \"encoder\": \"BERT\",\n",
    "    \"bert_path\": \"bert-base-cased\",  # Utiliser directement le nom du modèle Hugging Face\n",
    "    \"logger_type\": \"default\",  # Ajout de la clé logger_type au lieu de logger\n",
    "    \"log_path\": \"./logs\",\n",
    "    \"run_name\": \"nyt_run\",\n",
    "    \"run_id\": \"1\",\n",
    "    \"note\": \"Adaptation du notebook avec le dataset JSON\",\n",
    "    \"path_to_save_model\": \"./models\",\n",
    "    \"hyper_parameters\": {\n",
    "        \"batch_size\": 6,\n",
    "        \"max_seq_len\": 100,\n",
    "        \"sliding_len\": 20,\n",
    "        \"epochs\": 5,\n",
    "        \"seed\": 42,\n",
    "        \"shaking_type\": \"cln\",\n",
    "        \"inner_enc_type\": \"lstm\",\n",
    "        \"dist_emb_size\": 20,\n",
    "        \"ent_add_dist\": True,\n",
    "        \"rel_add_dist\": True,\n",
    "        \"lr\": 1e-5,\n",
    "        \"weight_decay\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Utiliser cette configuration au lieu d'importer config.py\n",
    "config = train_config\n",
    "hyper_parameters = config[\"hyper_parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer les répertoires nécessaires\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation du dispositif: cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config[\"device_num\"])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation du dispositif: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproductivity\n",
    "torch.manual_seed(hyper_parameters[\"seed\"]) # pytorch random seed\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin du fichier d'entraînement: nyt_dataset.json\n",
      "Chemin du fichier de validation: nyt_dataset.json\n",
      "Chemin du fichier rel2id: rel2id.json\n"
     ]
    }
   ],
   "source": [
    "# Définir les chemins d'accès aux fichiers\n",
    "# Utiliser des chemins directs pour éviter les problèmes\n",
    "train_data_path = config[\"train_data\"]\n",
    "valid_data_path = config[\"valid_data\"]\n",
    "rel2id_path = config[\"rel2id\"]\n",
    "\n",
    "print(f\"Chemin du fichier d'entraînement: {train_data_path}\")\n",
    "print(f\"Chemin du fichier de validation: {valid_data_path}\")\n",
    "print(f\"Chemin du fichier rel2id: {rel2id_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du logger simplifiée\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(os.path.join(config[\"log_path\"], \"training.log\")),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"TPLinker\")\n",
    "model_state_dict_dir = config[\"path_to_save_model\"]\n",
    "if not os.path.exists(model_state_dict_dir):\n",
    "    os.makedirs(model_state_dict_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 samples. Skipped 0 relations due to char/token mapping issues.\n",
      "\n",
      "nyt_dataset.json a été ÉCRASÉ par la version au format TPLinker (100 samples).\n",
      "\n",
      "Exemple d'entrée du dataset:\n",
      "{'classes': ['DEFAULT', 'DEFAULT'],\n",
      " 'entity_char_span_ends': [367, 248],\n",
      " 'entity_char_span_starts': [360, 238],\n",
      " 'entity_list': [{'char_span': [360, 367],\n",
      "                  'text': 'Angeles',\n",
      "                  'tok_span': [74, 75],\n",
      "                  'type': 'DEFAULT'},\n",
      "                 {'char_span': [238, 248],\n",
      "                  'text': 'California',\n",
      "                  'tok_span': [50, 51],\n",
      "                  'type': 'DEFAULT'}],\n",
      " 'event_list': [],\n",
      " 'id': 'train_42',\n",
      " 'obj_char_span_ends': [248],\n",
      " 'obj_char_span_starts': [238],\n",
      " 'predicates': ['/location/location/contains'],\n",
      " 'raw_entities': ['Angeles', 'California'],\n",
      " 'raw_objects': ['California'],\n",
      " 'raw_subjects': ['Angeles'],\n",
      " 'relation_list': [{'obj_char_span': [238, 248],\n",
      "                    'obj_tok_span': [50, 51],\n",
      "                    'object': 'California',\n",
      "                    'predicate': '/location/location/contains',\n",
      "                    'subj_char_span': [360, 367],\n",
      "                    'subj_tok_span': [74, 75],\n",
      "                    'subject': 'Angeles'}],\n",
      " 'subj_char_span_ends': [367],\n",
      " 'subj_char_span_starts': [360],\n",
      " 'text': 'The study -- which was carried out by researchers at the University '\n",
      "         'of Wisconsin and Seton Hall University in South Orange , N.J. , and '\n",
      "         'led by the Norman Lear Center at the Annenberg School for '\n",
      "         'Communication at the University of Southern California -- analyzed '\n",
      "         'more than 4,000 local newscasts that were broadcast in 11 major '\n",
      "         'markets , including New York , Los Angeles , Philadelphia and Miami '\n",
      "         ', in the four weeks before the election .'}\n",
      "\n",
      "Relation to ID mapping (rel2id):\n",
      "{'/business/company/founders': 0,\n",
      " '/business/company/place_founded': 1,\n",
      " '/business/person/company': 2,\n",
      " '/location/administrative_division/country': 3,\n",
      " '/location/country/administrative_divisions': 4,\n",
      " '/location/country/capital': 5,\n",
      " '/location/location/contains': 6,\n",
      " '/location/neighborhood/neighborhood_of': 7,\n",
      " '/people/deceased_person/place_of_death': 8,\n",
      " '/people/person/children': 9,\n",
      " '/people/person/nationality': 10,\n",
      " '/people/person/place_lived': 11,\n",
      " '/people/person/place_of_birth': 12,\n",
      " '/people/person/religion': 13}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "input_path = \"nyt_dataset.json\"\n",
    "output_prefix = \"nyt_dataset\"\n",
    "tokenizer_name = \"bert-base-cased\"  # ou ton tokenizer BiLSTM\n",
    "train_ratio = 0.8\n",
    "random_seed = 42\n",
    "\n",
    "# === CHARGEMENT ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    full_data = json.load(f)\n",
    "\n",
    "def char_to_token(offsets, char_index):\n",
    "    \"\"\"Mappe un index de caractère à un index de token BERT (WordPiece).\"\"\"\n",
    "    for idx, (start, end) in enumerate(offsets):\n",
    "        if start <= char_index < end:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def find_key(possibles, keys):\n",
    "    for k in possibles:\n",
    "        if k in keys:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "fixed_data = []\n",
    "skipped = 0\n",
    "\n",
    "for sample in full_data:\n",
    "    keys = sample.keys()\n",
    "    text_field = find_key([\"text\", \"sentence\", \"content\"], keys)\n",
    "    if not text_field:\n",
    "        continue\n",
    "    text = sample[text_field]\n",
    "    encoding = tokenizer(text, return_offsets_mapping=True, truncation=True, max_length=512)\n",
    "    offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "    subj_field = find_key([\"raw_subjects\", \"subjects\", \"subj\", \"subject\"], keys)\n",
    "    obj_field = find_key([\"raw_objects\", \"objects\", \"obj\", \"object\"], keys)\n",
    "    pred_field = find_key([\"predicates\", \"predicate\", \"relations\", \"relation\"], keys)\n",
    "    subj_start_field = find_key([\"subj_char_span_starts\", \"subject_start\", \"subj_starts\"], keys)\n",
    "    subj_end_field = find_key([\"subj_char_span_ends\", \"subject_end\", \"subj_ends\"], keys)\n",
    "    obj_start_field = find_key([\"obj_char_span_starts\", \"object_start\", \"obj_starts\"], keys)\n",
    "    obj_end_field = find_key([\"obj_char_span_ends\", \"object_end\", \"obj_ends\"], keys)\n",
    "\n",
    "    # === GENERATION DE RELATION_LIST ===\n",
    "    relation_list = []\n",
    "    if all([subj_field, obj_field, pred_field, subj_start_field, subj_end_field, obj_start_field, obj_end_field]):\n",
    "        subj_list = sample[subj_field]\n",
    "        obj_list = sample[obj_field]\n",
    "        pred_list = sample[pred_field]\n",
    "        subj_start_list = sample[subj_start_field]\n",
    "        subj_end_list = sample[subj_end_field]\n",
    "        obj_start_list = sample[obj_start_field]\n",
    "        obj_end_list = sample[obj_end_field]\n",
    "        num_rels = min(len(subj_list), len(obj_list), len(pred_list), len(subj_start_list), len(subj_end_list), len(obj_start_list), len(obj_end_list))\n",
    "        for i in range(num_rels):\n",
    "            subj, obj, pred = subj_list[i], obj_list[i], pred_list[i]\n",
    "            subj_char_start, subj_char_end = subj_start_list[i], subj_end_list[i]\n",
    "            obj_char_start, obj_char_end = obj_start_list[i], obj_end_list[i]\n",
    "            subj_tok_start = char_to_token(offsets, subj_char_start)\n",
    "            subj_tok_end = char_to_token(offsets, subj_char_end - 1)\n",
    "            obj_tok_start = char_to_token(offsets, obj_char_start)\n",
    "            obj_tok_end = char_to_token(offsets, obj_char_end - 1)\n",
    "            if None in (subj_tok_start, subj_tok_end, obj_tok_start, obj_tok_end):\n",
    "                skipped += 1\n",
    "                continue\n",
    "            relation_list.append({\n",
    "                \"predicate\": pred,\n",
    "                \"subject\": subj,\n",
    "                \"object\": obj,\n",
    "                \"subj_char_span\": [subj_char_start, subj_char_end],\n",
    "                \"obj_char_span\": [obj_char_start, obj_char_end],\n",
    "                \"subj_tok_span\": [subj_tok_start, subj_tok_end + 1],  # [start, end)\n",
    "                \"obj_tok_span\": [obj_tok_start, obj_tok_end + 1]\n",
    "            })\n",
    "    else:\n",
    "        print(f\"WARNING: Could not auto-detect relation fields for sample {sample.get('id', '?')}. Empty relation_list will be created.\")\n",
    "\n",
    "    sample[\"text\"] = text\n",
    "    sample[\"relation_list\"] = relation_list\n",
    "\n",
    "    # === entity_list (optionnel mais utile pour analyse ou débogage) ===\n",
    "    ent_field = find_key([\"raw_entities\", \"entities\", \"entity\"], keys)\n",
    "    ent_start_field = find_key([\"entity_char_span_starts\", \"entity_start\", \"ent_starts\"], keys)\n",
    "    ent_end_field = find_key([\"entity_char_span_ends\", \"entity_end\", \"ent_ends\"], keys)\n",
    "    ent_type_field = find_key([\"classes\", \"entity_types\", \"types\", \"labels\"], keys)\n",
    "    entity_list = []\n",
    "    if ent_field and ent_start_field and ent_end_field:\n",
    "        ent_list = sample[ent_field]\n",
    "        ent_start_list = sample[ent_start_field]\n",
    "        ent_end_list = sample[ent_end_field]\n",
    "        ent_type_list = sample.get(ent_type_field, [\"DEFAULT\"] * len(ent_list))\n",
    "        for i in range(min(len(ent_list), len(ent_start_list), len(ent_end_list), len(ent_type_list))):\n",
    "            ent = ent_list[i]\n",
    "            char_span = [ent_start_list[i], ent_end_list[i]]\n",
    "            tok_start = char_to_token(offsets, char_span[0])\n",
    "            tok_end = char_to_token(offsets, char_span[1] - 1)\n",
    "            entity_list.append({\n",
    "                \"text\": ent,\n",
    "                \"char_span\": char_span,\n",
    "                \"tok_span\": [tok_start, tok_end + 1] if tok_start is not None and tok_end is not None else [0, 1],\n",
    "                \"type\": ent_type_list[i]\n",
    "            })\n",
    "    # fallback: crée les entités à partir des relations (pas obligatoire)\n",
    "    elif relation_list:\n",
    "        ents = defaultdict(dict)\n",
    "        for rel in relation_list:\n",
    "            for role, key in [(\"subject\", \"subj_char_span\"), (\"object\", \"obj_char_span\")]:\n",
    "                ent_text = rel[role]\n",
    "                char_span = rel.get(f\"{role[:4]}_char_span\", None)\n",
    "                tok_span = rel.get(f\"{role[:4]}_tok_span\", None)\n",
    "                ent_type = \"DEFAULT\"\n",
    "                ent_id = (ent_text, tuple(char_span) if char_span else ())\n",
    "                if ent_id not in ents:\n",
    "                    ents[ent_id] = {\n",
    "                        \"text\": ent_text,\n",
    "                        \"char_span\": char_span if char_span else [0, 1],\n",
    "                        \"tok_span\": tok_span if tok_span else [0, 1],\n",
    "                        \"type\": ent_type\n",
    "                    }\n",
    "        entity_list = list(ents.values())\n",
    "    sample[\"entity_list\"] = entity_list\n",
    "    if \"event_list\" not in sample:\n",
    "        sample[\"event_list\"] = []\n",
    "    fixed_data.append(sample)\n",
    "\n",
    "print(f\"Processed {len(fixed_data)} samples. Skipped {skipped} relations due to char/token mapping issues.\")\n",
    "# === Sauvegarde et écrasement du nyt_dataset original avec la nouvelle structure ===\n",
    "with open(input_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(fixed_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nnyt_dataset.json a été ÉCRASÉ par la version au format TPLinker ({len(fixed_data)} samples).\")\n",
    "\n",
    "# === SHUFFLE & SPLIT ===\n",
    "random.seed(random_seed)\n",
    "random.shuffle(fixed_data)\n",
    "split_index = int(len(fixed_data) * train_ratio)\n",
    "train_data = fixed_data[:split_index]\n",
    "valid_data = fixed_data[split_index:]\n",
    "\n",
    "# === rel2id (pour TPLinker) ===\n",
    "all_predicates = set()\n",
    "for sample in train_data + valid_data:\n",
    "    for rel in sample[\"relation_list\"]:\n",
    "        all_predicates.add(rel[\"predicate\"])\n",
    "rel2id = {p: i for i, p in enumerate(sorted(all_predicates))}\n",
    "\n",
    "with open(f\"{output_prefix}_rel2id.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(rel2id, f, ensure_ascii=False, indent=2)\n",
    "with open(f\"{output_prefix}_train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "with open(f\"{output_prefix}_valid.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(valid_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nExemple d'entrée du dataset:\")\n",
    "pprint(train_data[0])\n",
    "# Sauvegarde du mapping relation -> id dans rel2id.json\n",
    "with open(f\"./rel2id.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(rel2id, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Affichage rel2id (console)\n",
    "print(\"\\nRelation to ID mapping (rel2id):\")\n",
    "pprint(rel2id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @specific\n",
    "if config[\"encoder\"] == \"BERT\":\n",
    "    # Correction de l'appel du tokenizer pour éviter l'erreur add_special_tokens\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(config[\"bert_path\"])\n",
    "    tokenize = tokenizer.tokenize\n",
    "    get_tok2char_span_map = lambda text: tokenizer.encode_plus(text, return_offsets_mapping=True)[\"offset_mapping\"]\n",
    "elif config[\"encoder\"] in {\"BiLSTM\", }:\n",
    "    tokenize = lambda text: text.split(\" \")\n",
    "    def get_tok2char_span_map(text):\n",
    "        tokens = text.split(\" \")\n",
    "        tok2char_span = []\n",
    "        char_num = 0\n",
    "        for tok in tokens:\n",
    "            tok2char_span.append((char_num, char_num + len(tok)))\n",
    "            char_num += len(tok) + 1 # +1: whitespace\n",
    "        return tok2char_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(tokenize_func = tokenize, \n",
    "                            get_tok2char_span_map_func = get_tok2char_span_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre maximum de tokens: 118\n"
     ]
    }
   ],
   "source": [
    "# train and valid max token num\n",
    "max_tok_num = 0\n",
    "all_data = train_data + valid_data \n",
    "    \n",
    "for sample in all_data:\n",
    "    tokens = tokenize(sample[\"text\"])\n",
    "    max_tok_num = max(max_tok_num, len(tokens))\n",
    "print(f\"Nombre maximum de tokens: {max_tok_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting into subtexts: 100%|██████████| 80/80 [00:00<00:00, 3118.35it/s]\n",
      "Splitting into subtexts: 100%|██████████| 20/20 [00:00<00:00, 3231.23it/s]\n"
     ]
    }
   ],
   "source": [
    "if max_tok_num > hyper_parameters[\"max_seq_len\"]:\n",
    "    train_data = preprocessor.split_into_short_samples(train_data, \n",
    "                                                          hyper_parameters[\"max_seq_len\"], \n",
    "                                                          sliding_len = hyper_parameters[\"sliding_len\"], \n",
    "                                                          encoder = config[\"encoder\"]\n",
    "                                                         )\n",
    "    valid_data = preprocessor.split_into_short_samples(valid_data, \n",
    "                                                          hyper_parameters[\"max_seq_len\"], \n",
    "                                                          sliding_len = hyper_parameters[\"sliding_len\"], \n",
    "                                                          encoder = config[\"encoder\"]\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 81 valid: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"train: {}\".format(len(train_data)), \"valid: {}\".format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = min(max_tok_num, hyper_parameters[\"max_seq_len\"])\n",
    "rel2id = json.load(open(\"rel2id.json\", \"r\", encoding = \"utf-8\"))\n",
    "handshaking_tagger = HandshakingTaggingScheme(rel2id = rel2id, max_seq_len = max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"encoder\"] == \"BERT\":\n",
    "    # Correction de l'appel du tokenizer pour éviter l'erreur add_special_tokens\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(config[\"bert_path\"])\n",
    "    data_maker = DataMaker4Bert(tokenizer, handshaking_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 81it [00:00, 4807.53it/s]\n",
      "Generate indexed train or valid data: 20it [00:00, 4339.01it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_train_data = data_maker.get_indexed_data(train_data, max_seq_len)\n",
    "indexed_valid_data = data_maker.get_indexed_data(valid_data, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple de texte:\n",
      "{'id': 'train_41', 'text': '', 'tok_offset': 0, 'char_offset': 0, 'event_list': [], 'entity_list': [{'text': 'Washington', 'char_span': [89, 99], 'tok_span': [18, 19], 'type': 'DEFAULT'}, {'text': 'Seattle', 'char_span': [51, 58], 'tok_span': [13, 14], 'type': 'DEFAULT'}], 'relation_list': [{'predicate': '/location/location/contains', 'subject': 'Washington', 'object': 'Seattle', 'subj_char_span': [89, 99], 'obj_char_span': [51, 58], 'subj_tok_span': [18, 19], 'obj_tok_span': [13, 14]}]}\n",
      "\n",
      "Tailles des tenseurs:\n",
      "batch_input_ids: torch.Size([6, 100])\n",
      "batch_attention_mask: torch.Size([6, 100])\n",
      "batch_token_type_ids: torch.Size([6, 100])\n",
      "offset_map_list: 6\n",
      "batch_ent_shaking_tag: 6\n",
      "batch_head_rel_shaking_tag: 6\n",
      "batch_tail_rel_shaking_tag: 6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Exemple simple de Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]  # Doit être un dict !\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    MyDataset(indexed_train_data),\n",
    "    batch_size=hyper_parameters[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    collate_fn=data_maker.generate_batch,\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    MyDataset(indexed_valid_data),\n",
    "    batch_size=hyper_parameters[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    collate_fn=data_maker.generate_batch,\n",
    ")\n",
    "\n",
    "# --- Visualisation d'un batch de données ---\n",
    "train_data_iter = iter(train_dataloader)\n",
    "batch_data = next(train_data_iter)\n",
    "text_list, batch_input_ids, \\\n",
    "batch_attention_mask, batch_token_type_ids, \\\n",
    "tok2char_span_list, batch_ent_shaking_tag, \\\n",
    "batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_data\n",
    "\n",
    "print(\"\\nExemple de texte:\")\n",
    "print(text_list[0])\n",
    "print()\n",
    "print(\"Tailles des tenseurs:\")\n",
    "print(f\"batch_input_ids: {batch_input_ids.size()}\")\n",
    "print(f\"batch_attention_mask: {batch_attention_mask.size()}\")\n",
    "print(f\"batch_token_type_ids: {batch_token_type_ids.size()}\")\n",
    "print(f\"offset_map_list: {len(tok2char_span_list)}\")\n",
    "print(f\"batch_ent_shaking_tag: {len(batch_ent_shaking_tag) if batch_ent_shaking_tag is not None else None}\")\n",
    "print(f\"batch_head_rel_shaking_tag: {len(batch_head_rel_shaking_tag) if batch_head_rel_shaking_tag is not None else None}\")\n",
    "print(f\"batch_tail_rel_shaking_tag: {len(batch_tail_rel_shaking_tag) if batch_tail_rel_shaking_tag is not None else None}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"encoder\"] == \"BERT\":\n",
    "    encoder = AutoModel.from_pretrained(config[\"bert_path\"])\n",
    "    hidden_size = encoder.config.hidden_size\n",
    "    rel_extractor = TPLinkerBert(encoder, \n",
    "                                 len(rel2id), \n",
    "                                 hyper_parameters[\"shaking_type\"],\n",
    "                                 hyper_parameters[\"inner_enc_type\"],\n",
    "                                 hyper_parameters[\"dist_emb_size\"],\n",
    "                                 hyper_parameters[\"ent_add_dist\"],\n",
    "                                 hyper_parameters[\"rel_add_dist\"],\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extractor = rel_extractor.to(device)\n",
    "\n",
    "# Définition de l'optimiseur\n",
    "optimizer = optim.Adam(rel_extractor.parameters(), lr = float(hyper_parameters[\"lr\"]), weight_decay = float(hyper_parameters[\"weight_decay\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'entraînement\n",
    "def train(dataloader, ep):\n",
    "    rel_extractor.train()\n",
    "    \n",
    "    total_loss = 0.\n",
    "    total_steps = len(dataloader)\n",
    "    for batch_ind, batch_data in enumerate(tqdm(dataloader, desc = \"Training\")):\n",
    "        text_id_list, text_list, batch_input_ids, \\\n",
    "        batch_attention_mask, batch_token_type_ids, \\\n",
    "        offset_map_list, batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_data\n",
    "        \n",
    "        batch_input_ids, batch_attention_mask, batch_token_type_ids = (\n",
    "            batch_input_ids.to(device),\n",
    "            batch_attention_mask.to(device),\n",
    "            batch_token_type_ids.to(device),\n",
    "        )\n",
    "        batch_ent_shaking_tag, batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = (\n",
    "            batch_ent_shaking_tag.to(device),\n",
    "            batch_head_rel_shaking_tag.to(device),\n",
    "            batch_tail_rel_shaking_tag.to(device),\n",
    "        )\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        loss = rel_extractor(\n",
    "            batch_input_ids, \n",
    "            batch_attention_mask, \n",
    "            batch_token_type_ids, \n",
    "            batch_ent_shaking_tag,\n",
    "            batch_head_rel_shaking_tag,\n",
    "            batch_tail_rel_shaking_tag,\n",
    "        )\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Log\n",
    "        if batch_ind % 10 == 0:\n",
    "            print(f\"Epoch {ep}, Batch {batch_ind}/{total_steps}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / total_steps\n",
    "    print(f\"Epoch {ep}, Average Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé à ./models/model.pt\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du modèle\n",
    "save_path = os.path.join(model_state_dict_dir, \"model.pt\")\n",
    "torch.save(rel_extractor.state_dict(), save_path)\n",
    "print(f\"Modèle sauvegardé à {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     from yaml import CLoader as Loader, CDumper as Dumper\n",
    "# except ImportError:\n",
    "#     from yaml import Loader, Dumper\n",
    "# config = yaml.load(open(\"train_config.yaml\", \"r\"), Loader = yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration manuelle pour éviter les problèmes de chemin\n",
    "train_config = {\n",
    "    \"exp_name\": \"nyt\",\n",
    "    \"data_home\": \".\",  # Utiliser le répertoire courant\n",
    "    \"train_data\": \"nyt_dataset.json\",  # Pointer directement vers le fichier JSON\n",
    "    \"valid_data\": \"nyt_dataset.json\",  # Utiliser le même fichier pour validation\n",
    "    \"rel2id\": \"./rel2id.json\",\n",
    "    \"device_num\": 0,\n",
    "    \"encoder\": \"BERT\",\n",
    "    \"model_state_dict_path\": \"./models/model.pt\",\n",
    "    \"bert_path\": \"bert-base-cased\",\n",
    "    \"log_path\": \"./logs/train.log\",\n",
    "    \"log_path\": \"./tplinker/logs\",\n",
    "    \"run_name\": \"nyt_run\",\n",
    "    \"run_id\": \"1\",\n",
    "    \"fr_scratch\":False,\n",
    "    \"note\": \"Adaptation du notebook avec le dataset JSON\",\n",
    "    \"path_to_save_model\": \"./models\",\n",
    "    \"logger\": \"wandb\",\n",
    "    \"hyper_parameters\": {\n",
    "        \"batch_size\": 6,\n",
    "        \"max_seq_len\": 100,\n",
    "        \"sliding_len\": 20,\n",
    "        \"epochs\": 5,\n",
    "        \"seed\": 42,\n",
    "        \"shaking_type\": \"cln\",\n",
    "        \"inner_enc_type\": \"lstm\",\n",
    "        \"dist_emb_size\": 20,\n",
    "        \"ent_add_dist\": True,\n",
    "        \"rel_add_dist\": True,\n",
    "        \"lr\": 1e-5,\n",
    "        \"weight_decay\": 0,\n",
    "        \"scheduler\":\"CAWR\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Utiliser cette configuration au lieu d'importer config.py\n",
    "config = train_config\n",
    "hyper_parameters = config[\"hyper_parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer les répertoires nécessaires\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation du dispositif: cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config[\"device_num\"])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation du dispositif: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproductivity\n",
    "torch.manual_seed(hyper_parameters[\"seed\"]) # pytorch random seed\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin du fichier d'entraînement: nyt_dataset.json\n",
      "Chemin du fichier de validation: nyt_dataset.json\n",
      "Chemin du fichier rel2id: ./rel2id.json\n"
     ]
    }
   ],
   "source": [
    "# Utiliser des chemins directs pour éviter les problèmes\n",
    "train_data_path = config[\"train_data\"]\n",
    "valid_data_path = config[\"valid_data\"]\n",
    "rel2id_path = config[\"rel2id\"]\n",
    "\n",
    "print(f\"Chemin du fichier d'entraînement: {train_data_path}\")\n",
    "print(f\"Chemin du fichier de validation: {valid_data_path}\")\n",
    "print(f\"Chemin du fichier rel2id: {rel2id_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = config[\"data_home\"]\n",
    "experiment_name = config[\"exp_name\"]    \n",
    "train_data_path = os.path.join(data_home, experiment_name, config[\"train_data\"])\n",
    "valid_data_path = os.path.join(data_home, experiment_name, config[\"valid_data\"])\n",
    "rel2id_path = os.path.join(data_home, experiment_name, config[\"rel2id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">nyt_run</strong> at: <a href='https://wandb.ai/annaki/nyt/runs/n99x8j7e' target=\"_blank\">https://wandb.ai/annaki/nyt/runs/n99x8j7e</a><br> View project at: <a href='https://wandb.ai/annaki/nyt' target=\"_blank\">https://wandb.ai/annaki/nyt</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250605_124006-n99x8j7e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e/Projects/tplinker/wandb/run-20250605_124241-1durnc6s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/annaki/nyt/runs/1durnc6s' target=\"_blank\">nyt_run</a></strong> to <a href='https://wandb.ai/annaki/nyt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/annaki/nyt' target=\"_blank\">https://wandb.ai/annaki/nyt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/annaki/nyt/runs/1durnc6s' target=\"_blank\">https://wandb.ai/annaki/nyt/runs/1durnc6s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "if config[\"logger\"] == \"wandb\":\n",
    "    # init wandb\n",
    "    wandb.init(project = experiment_name, \n",
    "               name = config[\"run_name\"],\n",
    "               config = hyper_parameters # Initialize config\n",
    "              )\n",
    "\n",
    "    wandb.config.note = config[\"note\"]          \n",
    "\n",
    "    model_state_dict_dir = wandb.run.dir\n",
    "    logger = wandb\n",
    "else:\n",
    "    logger = DefaultLogger(config[\"log_path\"], experiment_name, config[\"run_name\"], config[\"run_id\"], hyper_parameters)\n",
    "    model_state_dict_dir = config[\"path_to_save_model\"]\n",
    "    if not os.path.exists(model_state_dict_dir):\n",
    "        os.makedirs(model_state_dict_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Charger le dataset complet\n",
    "data_path = \"./nyt_dataset.json\"\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    full_data = json.load(f)\n",
    "\n",
    "# Mélanger les données\n",
    "random.seed(42)\n",
    "random.shuffle(full_data)\n",
    "\n",
    "# Split 80% train / 20% valid\n",
    "split_index = int(len(full_data) * 0.8)\n",
    "train_data = full_data[:split_index]\n",
    "valid_data = full_data[split_index:]\n",
    "\n",
    "# Sauvegarder dans le même dossier\n",
    "with open(\"./nyt_dataset_train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(\"./nyt_dataset_valid.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(valid_data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @specific\n",
    "if config[\"encoder\"] == \"BERT\":\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(config[\"bert_path\"], do_lower_case=False)\n",
    "    tokenize = tokenizer.tokenize\n",
    "    get_tok2char_span_map = lambda text: tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_offsets_mapping=True, \n",
    "        add_special_tokens=False\n",
    "    )[\"offset_mapping\"]\n",
    "\n",
    "elif config[\"encoder\"] in {\"BiLSTM\", }:\n",
    "    tokenize = lambda text: text.split(\" \")\n",
    "    def get_tok2char_span_map(text):\n",
    "        tokens = text.split(\" \")\n",
    "        tok2char_span = []\n",
    "        char_num = 0\n",
    "        for tok in tokens:\n",
    "            tok2char_span.append((char_num, char_num + len(tok)))\n",
    "            char_num += len(tok) + 1 # +1: whitespace\n",
    "        return tok2char_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(tokenize_func = tokenize, \n",
    "                            get_tok2char_span_map_func = get_tok2char_span_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and valid max token num\n",
    "max_tok_num = 0\n",
    "all_data = train_data + valid_data \n",
    "    \n",
    "for sample in all_data:\n",
    "    tokens = tokenize(sample[\"text\"])\n",
    "    max_tok_num = max(max_tok_num, len(tokens))\n",
    "max_tok_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting into subtexts: 100%|██████████| 80/80 [00:00<00:00, 2703.97it/s]\n",
      "Splitting into subtexts: 100%|██████████| 20/20 [00:00<00:00, 3055.96it/s]\n"
     ]
    }
   ],
   "source": [
    "if max_tok_num > hyper_parameters[\"max_seq_len\"]:\n",
    "    train_data = preprocessor.split_into_short_samples(train_data, \n",
    "                                                          hyper_parameters[\"max_seq_len\"], \n",
    "                                                          sliding_len = hyper_parameters[\"sliding_len\"], \n",
    "                                                          encoder = config[\"encoder\"]\n",
    "                                                         )\n",
    "    valid_data = preprocessor.split_into_short_samples(valid_data, \n",
    "                                                          hyper_parameters[\"max_seq_len\"], \n",
    "                                                          sliding_len = hyper_parameters[\"sliding_len\"], \n",
    "                                                          encoder = config[\"encoder\"]\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 81 valid: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"train: {}\".format(len(train_data)), \"valid: {}\".format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagger (Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = min(max_tok_num, hyper_parameters[\"max_seq_len\"])\n",
    "rel2id = json.load(open(\"./rel2id.json\", \"r\", encoding = \"utf-8\"))\n",
    "handshaking_tagger = HandshakingTaggingScheme(rel2id = rel2id, max_seq_len = max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"encoder\"] == \"BERT\":\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(config[\"bert_path\"], do_lower_case=False)\n",
    "    data_maker = DataMaker4Bert(tokenizer, handshaking_tagger)\n",
    "\n",
    "    \n",
    "elif config[\"encoder\"] in {\"BiLSTM\", }:\n",
    "    token2idx_path = os.path.join(data_home, experiment_name, config[\"token2idx\"])\n",
    "    token2idx = json.load(open(token2idx_path, \"r\", encoding = \"utf-8\"))\n",
    "    idx2token = {idx:tok for tok, idx in token2idx.items()}\n",
    "    def text2indices(text, max_seq_len):\n",
    "        input_ids = []\n",
    "        tokens = text.split(\" \")\n",
    "        for tok in tokens:\n",
    "            if tok not in token2idx:\n",
    "                input_ids.append(token2idx['<UNK>'])\n",
    "            else:\n",
    "                input_ids.append(token2idx[tok])\n",
    "        if len(input_ids) < max_seq_len:\n",
    "            input_ids.extend([token2idx['<PAD>']] * (max_seq_len - len(input_ids)))\n",
    "        input_ids = torch.tensor(input_ids[:max_seq_len])\n",
    "        return input_ids\n",
    "    data_maker = DataMaker4BiLSTM(text2indices, get_tok2char_span_map, handshaking_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 81it [00:00, 1872.11it/s]\n",
      "Generate indexed train or valid data: 20it [00:00, 1574.59it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "indexed_train_data = data_maker.get_indexed_data(train_data, max_seq_len)\n",
    "indexed_valid_data = data_maker.get_indexed_data(valid_data, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(MyDataset(indexed_train_data), \n",
    "                                  batch_size = hyper_parameters[\"batch_size\"], \n",
    "                                  shuffle = True, \n",
    "                                  num_workers = 6,\n",
    "                                  drop_last = False,\n",
    "                                  collate_fn = data_maker.generate_batch,\n",
    "                                 )\n",
    "valid_dataloader = DataLoader(MyDataset(indexed_valid_data), \n",
    "                          batch_size = hyper_parameters[\"batch_size\"], \n",
    "                          shuffle = True, \n",
    "                          num_workers = 6,\n",
    "                          drop_last = False,\n",
    "                          collate_fn = data_maker.generate_batch,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # have a look at dataloader\n",
    "# train_data_iter = iter(train_dataloader)\n",
    "# batch_data = next(train_data_iter)\n",
    "# text_id_list, text_list, batch_input_ids, \\\n",
    "# batch_attention_mask, batch_token_type_ids, \\\n",
    "# offset_map_list, batch_ent_shaking_tag, \\\n",
    "# batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_data\n",
    "\n",
    "# print(text_list[0])\n",
    "# print()\n",
    "# print(tokenizer.decode(batch_input_ids[0].tolist()))\n",
    "# print(batch_input_ids.size())\n",
    "# print(batch_attention_mask.size())\n",
    "# print(batch_token_type_ids.size())\n",
    "# print(len(offset_map_list))\n",
    "# print(batch_ent_shaking_tag.size())\n",
    "# print(batch_head_rel_shaking_tag.size())\n",
    "# print(batch_tail_rel_shaking_tag.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"encoder\"] == \"BERT\":\n",
    "    encoder = AutoModel.from_pretrained(config[\"bert_path\"])\n",
    "    hidden_size = encoder.config.hidden_size\n",
    "    rel_extractor = TPLinkerBert(encoder, \n",
    "                                 len(rel2id), \n",
    "                                 hyper_parameters[\"shaking_type\"],\n",
    "                                 hyper_parameters[\"inner_enc_type\"],\n",
    "                                 hyper_parameters[\"dist_emb_size\"],\n",
    "                                 hyper_parameters[\"ent_add_dist\"],\n",
    "                                 hyper_parameters[\"rel_add_dist\"],\n",
    "                                )\n",
    "    \n",
    "elif config[\"encoder\"] in {\"BiLSTM\", }:\n",
    "    glove = Glove()\n",
    "    glove = glove.load(config[\"pretrained_word_embedding_path\"])\n",
    "    \n",
    "    # prepare embedding matrix\n",
    "    word_embedding_init_matrix = np.random.normal(-1, 1, size=(len(token2idx), hyper_parameters[\"word_embedding_dim\"]))\n",
    "    count_in = 0\n",
    "\n",
    "    # 在预训练词向量中的用该预训练向量\n",
    "    # 不在预训练集里的用随机向量\n",
    "    for ind, tok in tqdm(idx2token.items(), desc=\"Embedding matrix initializing...\"):\n",
    "        if tok in glove.dictionary:\n",
    "            count_in += 1\n",
    "            word_embedding_init_matrix[ind] = glove.word_vectors[glove.dictionary[tok]]\n",
    "\n",
    "    print(\"{:.4f} tokens are in the pretrain word embedding matrix\".format(count_in / len(idx2token))) # 命中预训练词向量的比例\n",
    "    word_embedding_init_matrix = torch.FloatTensor(word_embedding_init_matrix)\n",
    "    \n",
    "    rel_extractor = TPLinkerBiLSTM(word_embedding_init_matrix, \n",
    "                                   hyper_parameters[\"emb_dropout\"], \n",
    "                                   hyper_parameters[\"enc_hidden_size\"], \n",
    "                                   hyper_parameters[\"dec_hidden_size\"],\n",
    "                                   hyper_parameters[\"rnn_dropout\"],\n",
    "                                   len(rel2id), \n",
    "                                   hyper_parameters[\"shaking_type\"],\n",
    "                                   hyper_parameters[\"inner_enc_type\"],\n",
    "                                   hyper_parameters[\"dist_emb_size\"],\n",
    "                                   hyper_parameters[\"ent_add_dist\"],\n",
    "                                   hyper_parameters[\"rel_add_dist\"],\n",
    "                                  )\n",
    "\n",
    "rel_extractor = rel_extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_paras = sum(x.numel() for x in rel_extractor.parameters())\n",
    "# enc_paras = sum(x.numel() for x in encoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_paras, enc_paras)\n",
    "# print(all_paras - enc_paras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_loss(weights = None):\n",
    "    if weights is not None:\n",
    "        weights = torch.FloatTensor(weights).to(device)\n",
    "    cross_en = nn.CrossEntropyLoss(weight = weights)  \n",
    "    return lambda pred, target: cross_en(pred.view(-1, pred.size()[-1]), target.view(-1))\n",
    "loss_func = bias_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsCalculator(handshaking_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train step\n",
    "def train_step(batch_train_data, optimizer, loss_weights):\n",
    "    if config[\"encoder\"] == \"BERT\":\n",
    "        sample_list, batch_input_ids, \\\n",
    "        batch_attention_mask, batch_token_type_ids, \\\n",
    "        tok2char_span_list, batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_train_data\n",
    "        \n",
    "        batch_input_ids, \\\n",
    "        batch_attention_mask, \\\n",
    "        batch_token_type_ids, \\\n",
    "        batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, \\\n",
    "        batch_tail_rel_shaking_tag = (batch_input_ids.to(device), \n",
    "                                      batch_attention_mask.to(device), \n",
    "                                      batch_token_type_ids.to(device), \n",
    "                                      batch_ent_shaking_tag.to(device), \n",
    "                                      batch_head_rel_shaking_tag.to(device), \n",
    "                                      batch_tail_rel_shaking_tag.to(device)\n",
    "                                     )\n",
    "        \n",
    "    elif config[\"encoder\"] in {\"BiLSTM\", }:\n",
    "        sample_list, batch_input_ids, \\\n",
    "        tok2char_span_list, batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_train_data\n",
    "        \n",
    "        batch_input_ids, \\\n",
    "        batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, \\\n",
    "        batch_tail_rel_shaking_tag = (batch_input_ids.to(device), \n",
    "                                      batch_ent_shaking_tag.to(device), \n",
    "                                      batch_head_rel_shaking_tag.to(device), \n",
    "                                      batch_tail_rel_shaking_tag.to(device)\n",
    "                                     )\n",
    "    \n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if config[\"encoder\"] == \"BERT\":\n",
    "        ent_shaking_outputs, \\\n",
    "        head_rel_shaking_outputs, \\\n",
    "        tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                                  batch_attention_mask, \n",
    "                                                  batch_token_type_ids, \n",
    "                                                 )\n",
    "    elif config[\"encoder\"] in {\"BiLSTM\", }:\n",
    "        ent_shaking_outputs, \\\n",
    "        head_rel_shaking_outputs, \\\n",
    "        tail_rel_shaking_outputs = rel_extractor(batch_input_ids)\n",
    "    \n",
    "    w_ent, w_rel = loss_weights[\"ent\"], loss_weights[\"rel\"]\n",
    "    loss = w_ent * loss_func(ent_shaking_outputs, batch_ent_shaking_tag) + \\\n",
    "            w_rel * loss_func(head_rel_shaking_outputs, batch_head_rel_shaking_tag) + \\\n",
    "            w_rel * loss_func(tail_rel_shaking_outputs, batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    ent_sample_acc = metrics.get_sample_accuracy(ent_shaking_outputs, \n",
    "                                          batch_ent_shaking_tag)\n",
    "    head_rel_sample_acc = metrics.get_sample_accuracy(head_rel_shaking_outputs, \n",
    "                                             batch_head_rel_shaking_tag)\n",
    "    tail_rel_sample_acc = metrics.get_sample_accuracy(tail_rel_shaking_outputs, \n",
    "                                             batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    return loss.item(), ent_sample_acc.item(), head_rel_sample_acc.item(), tail_rel_sample_acc.item()\n",
    "\n",
    "# valid step\n",
    "def valid_step(batch_valid_data):\n",
    "    if config[\"encoder\"] == \"BERT\":\n",
    "        sample_list, batch_input_ids, \\\n",
    "        batch_attention_mask, batch_token_type_ids, \\\n",
    "        tok2char_span_list, batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_valid_data\n",
    "        \n",
    "        batch_input_ids, \\\n",
    "        batch_attention_mask, \\\n",
    "        batch_token_type_ids, \\\n",
    "        batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, \\\n",
    "        batch_tail_rel_shaking_tag = (batch_input_ids.to(device), \n",
    "                                      batch_attention_mask.to(device), \n",
    "                                      batch_token_type_ids.to(device), \n",
    "                                      batch_ent_shaking_tag.to(device), \n",
    "                                      batch_head_rel_shaking_tag.to(device), \n",
    "                                      batch_tail_rel_shaking_tag.to(device)\n",
    "                                     )\n",
    "        \n",
    "    elif config[\"encoder\"] in {\"BiLSTM\", }:\n",
    "        sample_list, batch_input_ids, \\\n",
    "        tok2char_span_list, batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_valid_data\n",
    "        \n",
    "        batch_input_ids, \\\n",
    "        batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, \\\n",
    "        batch_tail_rel_shaking_tag = (batch_input_ids.to(device), \n",
    "                                      batch_ent_shaking_tag.to(device), \n",
    "                                      batch_head_rel_shaking_tag.to(device), \n",
    "                                      batch_tail_rel_shaking_tag.to(device)\n",
    "                                     )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if config[\"encoder\"] == \"BERT\":\n",
    "            ent_shaking_outputs, \\\n",
    "            head_rel_shaking_outputs, \\\n",
    "            tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                                      batch_attention_mask, \n",
    "                                                      batch_token_type_ids, \n",
    "                                                     )\n",
    "        elif config[\"encoder\"] in {\"BiLSTM\", }:\n",
    "            ent_shaking_outputs, \\\n",
    "            head_rel_shaking_outputs, \\\n",
    "            tail_rel_shaking_outputs = rel_extractor(batch_input_ids)\n",
    "\n",
    "    \n",
    "    ent_sample_acc = metrics.get_sample_accuracy(ent_shaking_outputs, \n",
    "                                          batch_ent_shaking_tag)\n",
    "    head_rel_sample_acc = metrics.get_sample_accuracy(head_rel_shaking_outputs, \n",
    "                                             batch_head_rel_shaking_tag)\n",
    "    tail_rel_sample_acc = metrics.get_sample_accuracy(tail_rel_shaking_outputs, \n",
    "                                             batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    rel_cpg = metrics.get_rel_cpg(sample_list, tok2char_span_list, \n",
    "                                    ent_shaking_outputs,\n",
    "                                    head_rel_shaking_outputs,\n",
    "                                    tail_rel_shaking_outputs,\n",
    "                                    hyper_parameters[\"match_pattern\"]\n",
    "                                    )\n",
    "    \n",
    "    return ent_sample_acc.item(), head_rel_sample_acc.item(), tail_rel_sample_acc.item(), rel_cpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1 = 0.\n",
    "def train_n_valid(train_dataloader, dev_dataloader, optimizer, scheduler, num_epoch):  \n",
    "    def train(dataloader, ep):\n",
    "        # train\n",
    "        rel_extractor.train()\n",
    "        \n",
    "        t_ep = time.time()\n",
    "        start_lr = optimizer.param_groups[0]['lr']\n",
    "        total_loss, total_ent_sample_acc, total_head_rel_sample_acc, total_tail_rel_sample_acc = 0., 0., 0., 0.\n",
    "        for batch_ind, batch_train_data in enumerate(dataloader):\n",
    "            t_batch = time.time()\n",
    "            z = (2 * len(rel2id) + 1)\n",
    "            steps_per_ep = len(dataloader)\n",
    "            total_steps = hyper_parameters[\"loss_weight_recover_steps\"] + 1 # + 1 avoid division by zero error\n",
    "            current_step = steps_per_ep * ep + batch_ind\n",
    "            w_ent = max(1 / z + 1 - current_step / total_steps, 1 / z)\n",
    "            w_rel = min((len(rel2id) / z) * current_step / total_steps, (len(rel2id) / z))\n",
    "            loss_weights = {\"ent\": w_ent, \"rel\": w_rel}\n",
    "            \n",
    "            loss, ent_sample_acc, head_rel_sample_acc, tail_rel_sample_acc = train_step(batch_train_data, optimizer, loss_weights)\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss\n",
    "            total_ent_sample_acc += ent_sample_acc\n",
    "            total_head_rel_sample_acc += head_rel_sample_acc\n",
    "            total_tail_rel_sample_acc += tail_rel_sample_acc\n",
    "            \n",
    "            avg_loss = total_loss / (batch_ind + 1)\n",
    "            avg_ent_sample_acc = total_ent_sample_acc / (batch_ind + 1)\n",
    "            avg_head_rel_sample_acc = total_head_rel_sample_acc / (batch_ind + 1)\n",
    "            avg_tail_rel_sample_acc = total_tail_rel_sample_acc / (batch_ind + 1)\n",
    "            \n",
    "            batch_print_format = \"\\rproject: {}, run_name: {}, Epoch: {}/{}, batch: {}/{}, train_loss: {}, \" + \\\n",
    "                                \"t_ent_sample_acc: {}, t_head_rel_sample_acc: {}, t_tail_rel_sample_acc: {},\" + \\\n",
    "                                 \"lr: {}, batch_time: {}, total_time: {} -------------\"\n",
    "                    \n",
    "            print(batch_print_format.format(experiment_name, config[\"run_name\"], \n",
    "                                            ep + 1, num_epoch, \n",
    "                                            batch_ind + 1, len(dataloader), \n",
    "                                            avg_loss, \n",
    "                                            avg_ent_sample_acc,\n",
    "                                            avg_head_rel_sample_acc,\n",
    "                                            avg_tail_rel_sample_acc,\n",
    "                                            optimizer.param_groups[0]['lr'],\n",
    "                                            time.time() - t_batch,\n",
    "                                            time.time() - t_ep,\n",
    "                                           ), end=\"\")\n",
    "            \n",
    "            if config[\"logger\"] == \"wandb\" and batch_ind % hyper_parameters[\"log_interval\"] == 0:\n",
    "                logger.log({\n",
    "                    \"train_loss\": avg_loss,\n",
    "                    \"train_ent_seq_acc\": avg_ent_sample_acc,\n",
    "                    \"train_head_rel_acc\": avg_head_rel_sample_acc,\n",
    "                    \"train_tail_rel_acc\": avg_tail_rel_sample_acc,\n",
    "                    \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "                    \"time\": time.time() - t_ep,\n",
    "                })\n",
    "                \n",
    "        if config[\"logger\"] != \"wandb\": # only log once for training if logger is not wandb\n",
    "                logger.log({\n",
    "                    \"train_loss\": avg_loss,\n",
    "                    \"train_ent_seq_acc\": avg_ent_sample_acc,\n",
    "                    \"train_head_rel_acc\": avg_head_rel_sample_acc,\n",
    "                    \"train_tail_rel_acc\": avg_tail_rel_sample_acc,\n",
    "                    \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "                    \"time\": time.time() - t_ep,\n",
    "                }) \n",
    "            \n",
    "        \n",
    "    def valid(dataloader, ep):\n",
    "        # valid\n",
    "        rel_extractor.eval()\n",
    "        \n",
    "        t_ep = time.time()\n",
    "        total_ent_sample_acc, total_head_rel_sample_acc, total_tail_rel_sample_acc = 0., 0., 0.\n",
    "        total_rel_correct_num, total_rel_pred_num, total_rel_gold_num = 0, 0, 0\n",
    "        for batch_ind, batch_valid_data in enumerate(tqdm(dataloader, desc = \"Validating\")):\n",
    "            ent_sample_acc, head_rel_sample_acc, tail_rel_sample_acc, rel_cpg = valid_step(batch_valid_data)\n",
    "\n",
    "            total_ent_sample_acc += ent_sample_acc\n",
    "            total_head_rel_sample_acc += head_rel_sample_acc\n",
    "            total_tail_rel_sample_acc += tail_rel_sample_acc\n",
    "            \n",
    "            total_rel_correct_num += rel_cpg[0]\n",
    "            total_rel_pred_num += rel_cpg[1]\n",
    "            total_rel_gold_num += rel_cpg[2]\n",
    "\n",
    "        avg_ent_sample_acc = total_ent_sample_acc / len(dataloader)\n",
    "        avg_head_rel_sample_acc = total_head_rel_sample_acc / len(dataloader)\n",
    "        avg_tail_rel_sample_acc = total_tail_rel_sample_acc / len(dataloader)\n",
    "        \n",
    "        rel_prf = metrics.get_prf_scores(total_rel_correct_num, total_rel_pred_num, total_rel_gold_num)\n",
    "        \n",
    "        log_dict = {\n",
    "                        \"val_ent_seq_acc\": avg_ent_sample_acc,\n",
    "                        \"val_head_rel_acc\": avg_head_rel_sample_acc,\n",
    "                        \"val_tail_rel_acc\": avg_tail_rel_sample_acc,\n",
    "                        \"val_prec\": rel_prf[0],\n",
    "                        \"val_recall\": rel_prf[1],\n",
    "                        \"val_f1\": rel_prf[2],\n",
    "                        \"time\": time.time() - t_ep,\n",
    "                    }\n",
    "        logger.log(log_dict)\n",
    "        pprint(log_dict)\n",
    "        \n",
    "        return rel_prf[2]\n",
    "        \n",
    "    for ep in range(num_epoch):\n",
    "        train(train_dataloader, ep)   \n",
    "        valid_f1 = valid(valid_dataloader, ep)\n",
    "        \n",
    "        global max_f1\n",
    "        if valid_f1 >= max_f1: \n",
    "            max_f1 = valid_f1\n",
    "            if valid_f1 > config[\"f1_2_save\"]: # save the best model\n",
    "                modle_state_num = len(glob.glob(model_state_dict_dir + \"/model_state_dict_*.pt\"))\n",
    "                torch.save(rel_extractor.state_dict(), os.path.join(model_state_dict_dir, \"model_state_dict_{}.pt\".format(modle_state_num)))\n",
    "#                 scheduler_state_num = len(glob.glob(schedule_state_dict_dir + \"/scheduler_state_dict_*.pt\"))\n",
    "#                 torch.save(scheduler.state_dict(), os.path.join(schedule_state_dict_dir, \"scheduler_state_dict_{}.pt\".format(scheduler_state_num))) \n",
    "        print(\"Current avf_f1: {}, Best f1: {}\".format(valid_f1, max_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler: CosineAnnealingWarmRestarts, T_0=28, T_mult=2\n"
     ]
    }
   ],
   "source": [
    "# Hyperparamètres\n",
    "hyper_parameters = {\n",
    "    \"lr\": 1e-4,\n",
    "    \"scheduler\": \"CAWR\",    # ou \"Step\"\n",
    "    \"T_mult\": 2,\n",
    "    \"rewarm_epoch_num\": 2,\n",
    "    \"decay_rate\": 0.5,\n",
    "    \"decay_steps\": 5\n",
    "}\n",
    "\n",
    "# Initialisation de l'optimizer\n",
    "init_learning_rate = float(hyper_parameters[\"lr\"])\n",
    "optimizer = torch.optim.Adam(rel_extractor.parameters(), lr=init_learning_rate)\n",
    "\n",
    "# Scheduler\n",
    "if hyper_parameters.get(\"scheduler\", None) == \"CAWR\":\n",
    "    T_mult = hyper_parameters.get(\"T_mult\", 1)  # valeur par défaut 1 si absent\n",
    "    rewarm_epoch_num = hyper_parameters.get(\"rewarm_epoch_num\", 2)\n",
    "    first_cycle_steps = len(train_dataloader) * rewarm_epoch_num\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=first_cycle_steps,\n",
    "        T_mult=T_mult\n",
    "    )\n",
    "    print(f\"Scheduler: CosineAnnealingWarmRestarts, T_0={first_cycle_steps}, T_mult={T_mult}\")\n",
    "\n",
    "elif hyper_parameters.get(\"scheduler\", None) == \"Step\":\n",
    "    decay_rate = hyper_parameters.get(\"decay_rate\", 0.5)\n",
    "    decay_steps = hyper_parameters.get(\"decay_steps\", 5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=decay_steps,\n",
    "        gamma=decay_rate\n",
    "    )\n",
    "    print(f\"Scheduler: StepLR, step_size={decay_steps}, gamma={decay_rate}\")\n",
    "else:\n",
    "    scheduler = None\n",
    "    print(\"Scheduler not specified or not recognized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296720/3849783542.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rel_extractor.load_state_dict(torch.load(model_state_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------model state model.pt loaded ----------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[348]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m     rel_extractor.load_state_dict(torch.load(model_state_path))\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m------------model state \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m loaded ----------------\u001b[39m\u001b[33m\"\u001b[39m.format(model_state_path.split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m]))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m train_n_valid(train_dataloader, valid_dataloader, optimizer, scheduler, \u001b[43mhyper_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mKeyError\u001b[39m: 'epochs'"
     ]
    }
   ],
   "source": [
    "if not config[\"fr_scratch\"]:\n",
    "    model_state_path = config[\"model_state_dict_path\"]\n",
    "    rel_extractor.load_state_dict(torch.load(model_state_path))\n",
    "    print(\"------------model state {} loaded ----------------\".format(model_state_path.split(\"/\")[-1]))\n",
    "\n",
    "train_n_valid(train_dataloader, valid_dataloader, optimizer, scheduler, hyper_parameters[\"epochs\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
